{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import h5py\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, data_root, target_size=(512, 512), bgr2rgb=True):\n",
    "        self.hypers = []\n",
    "        self.bgrs = []\n",
    "        hyper_data_path = f'{data_root}/Train_spectral/'\n",
    "        bgr_data_path = f'{data_root}/Train_RGB/'\n",
    "        with open(f'{data_root}/split_txt/Train_list.txt', 'r') as fin:\n",
    "            hyper_list = [line.replace('\\n', '.mat') for line in fin]\n",
    "            bgr_list = [line.replace('mat','jpg') for line in hyper_list]\n",
    "        hyper_list.sort()\n",
    "        bgr_list.sort()\n",
    "        print(f'len(hyper_Train) of ntire2022 dataset:{len(hyper_list)}')\n",
    "        print(f'len(bgr_Train) of ntire2022 dataset:{len(bgr_list)}')\n",
    "        for i in range(len(hyper_list)):\n",
    "            hyper_path = hyper_data_path + hyper_list[i]\n",
    "            if 'mat' not in hyper_path:\n",
    "                continue\n",
    "            with h5py.File(hyper_path, 'r') as mat:\n",
    "                hyper = np.float32(np.array(mat['cube']))\n",
    "            hyper = np.transpose(hyper, [0, 2, 1])\n",
    "            bgr_path = bgr_data_path + bgr_list[i]\n",
    "            assert hyper_list[i].split('.')[0] == bgr_list[i].split('.')[0], 'Hyper and RGB come from different scenes.'\n",
    "            bgr = cv2.imread(bgr_path)\n",
    "            if bgr2rgb:\n",
    "                bgr = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "            bgr = np.float32(bgr)\n",
    "            bgr = (bgr - bgr.min()) / (bgr.max() - bgr.min())\n",
    "            bgr = np.transpose(bgr, [2, 0, 1])\n",
    "            self.hypers.append(hyper)\n",
    "            self.bgrs.append(bgr)\n",
    "            mat.close()\n",
    "            print(f'Ntire2022 scene {i} is loaded.')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        hyper = self.hypers[idx]\n",
    "        bgr = self.bgrs[idx]\n",
    "        target_size = (512,512)\n",
    "        # Resize both hyper and bgr images to the target size\n",
    "        hyper = cv2.resize(hyper.transpose(1, 2, 0), target_size).transpose(2, 0, 1)\n",
    "        bgr = cv2.resize(bgr.transpose(1, 2, 0), target_size).transpose(2, 0, 1)\n",
    "        \n",
    "        return np.ascontiguousarray(bgr), np.ascontiguousarray(hyper)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hypers)\n",
    "\n",
    "class ValidDataset(Dataset):\n",
    "    def __init__(self, data_root, target_size=(512, 512), bgr2rgb=True):\n",
    "        self.hypers = []\n",
    "        self.bgrs = []\n",
    "        hyper_data_path = f'{data_root}/Valid_spectral/'\n",
    "        bgr_data_path = f'{data_root}/Valid_RGB/'\n",
    "        with open(f'{data_root}/split_txt/valid_list.txt', 'r') as fin:\n",
    "            hyper_list = [line.replace('\\n', '.mat') for line in fin]\n",
    "            bgr_list = [line.replace('mat','jpg') for line in hyper_list]\n",
    "        hyper_list.sort()\n",
    "        bgr_list.sort()\n",
    "        print(f'len(hyper_valid) of ntire2022 dataset:{len(hyper_list)}')\n",
    "        print(f'len(bgr_valid) of ntire2022 dataset:{len(bgr_list)}')\n",
    "        for i in range(len(hyper_list)):\n",
    "            hyper_path = hyper_data_path + hyper_list[i]\n",
    "            if 'mat' not in hyper_path:\n",
    "                continue\n",
    "            with h5py.File(hyper_path, 'r') as mat:\n",
    "                hyper = np.float32(np.array(mat['cube']))\n",
    "            hyper = np.transpose(hyper, [0, 2, 1])\n",
    "            bgr_path = bgr_data_path + bgr_list[i]\n",
    "            assert hyper_list[i].split('.')[0] == bgr_list[i].split('.')[0], 'Hyper and RGB come from different scenes.'\n",
    "            bgr = cv2.imread(bgr_path)\n",
    "            if bgr2rgb:\n",
    "                bgr = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "            bgr = np.float32(bgr)\n",
    "            bgr = (bgr - bgr.min()) / (bgr.max() - bgr.min())\n",
    "            bgr = np.transpose(bgr, [2, 0, 1])\n",
    "            self.hypers.append(hyper)\n",
    "            self.bgrs.append(bgr)\n",
    "            mat.close()\n",
    "            print(f'Ntire2022 scene {i} is loaded.')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        hyper = self.hypers[idx]\n",
    "        bgr = self.bgrs[idx]\n",
    "#         print(hyper.shape)\n",
    "        \n",
    "        target_size = (512,512)\n",
    "        # Resize both hyper and bgr images to the target size\n",
    "        hyper = cv2.resize(hyper.transpose(1, 2, 0), target_size).transpose(2, 0, 1)\n",
    "        bgr = cv2.resize(bgr.transpose(1, 2, 0), target_size).transpose(2, 0, 1)\n",
    "#         print(hyper.shape)\n",
    "        return np.ascontiguousarray(bgr), np.ascontiguousarray(hyper)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(hyper_Train) of ntire2022 dataset:797\n",
      "len(bgr_Train) of ntire2022 dataset:797\n",
      "Ntire2022 scene 0 is loaded.\n",
      "Ntire2022 scene 1 is loaded.\n",
      "Ntire2022 scene 2 is loaded.\n",
      "Ntire2022 scene 3 is loaded.\n",
      "Ntire2022 scene 4 is loaded.\n",
      "Ntire2022 scene 5 is loaded.\n",
      "Ntire2022 scene 6 is loaded.\n",
      "Ntire2022 scene 7 is loaded.\n",
      "Ntire2022 scene 8 is loaded.\n",
      "Ntire2022 scene 9 is loaded.\n",
      "Ntire2022 scene 10 is loaded.\n",
      "Ntire2022 scene 11 is loaded.\n",
      "Ntire2022 scene 12 is loaded.\n",
      "Ntire2022 scene 13 is loaded.\n",
      "Ntire2022 scene 14 is loaded.\n",
      "Ntire2022 scene 15 is loaded.\n",
      "Ntire2022 scene 16 is loaded.\n",
      "Ntire2022 scene 17 is loaded.\n",
      "Ntire2022 scene 18 is loaded.\n",
      "Ntire2022 scene 19 is loaded.\n",
      "Ntire2022 scene 20 is loaded.\n",
      "Ntire2022 scene 21 is loaded.\n",
      "Ntire2022 scene 22 is loaded.\n",
      "Ntire2022 scene 23 is loaded.\n",
      "Ntire2022 scene 24 is loaded.\n",
      "Ntire2022 scene 25 is loaded.\n",
      "Ntire2022 scene 26 is loaded.\n",
      "Ntire2022 scene 27 is loaded.\n",
      "Ntire2022 scene 28 is loaded.\n",
      "Ntire2022 scene 29 is loaded.\n",
      "Ntire2022 scene 30 is loaded.\n",
      "Ntire2022 scene 31 is loaded.\n",
      "Ntire2022 scene 32 is loaded.\n",
      "Ntire2022 scene 33 is loaded.\n",
      "Ntire2022 scene 34 is loaded.\n",
      "Ntire2022 scene 35 is loaded.\n",
      "Ntire2022 scene 36 is loaded.\n",
      "Ntire2022 scene 37 is loaded.\n",
      "Ntire2022 scene 38 is loaded.\n",
      "Ntire2022 scene 39 is loaded.\n",
      "Ntire2022 scene 40 is loaded.\n",
      "Ntire2022 scene 41 is loaded.\n",
      "Ntire2022 scene 42 is loaded.\n",
      "Ntire2022 scene 43 is loaded.\n",
      "Ntire2022 scene 44 is loaded.\n",
      "Ntire2022 scene 45 is loaded.\n",
      "Ntire2022 scene 46 is loaded.\n",
      "Ntire2022 scene 47 is loaded.\n",
      "Ntire2022 scene 48 is loaded.\n",
      "Ntire2022 scene 49 is loaded.\n",
      "Ntire2022 scene 50 is loaded.\n",
      "Ntire2022 scene 51 is loaded.\n",
      "Ntire2022 scene 52 is loaded.\n",
      "Ntire2022 scene 53 is loaded.\n",
      "Ntire2022 scene 54 is loaded.\n",
      "Ntire2022 scene 55 is loaded.\n",
      "Ntire2022 scene 56 is loaded.\n",
      "Ntire2022 scene 57 is loaded.\n",
      "Ntire2022 scene 58 is loaded.\n",
      "Ntire2022 scene 59 is loaded.\n",
      "Ntire2022 scene 60 is loaded.\n",
      "Ntire2022 scene 61 is loaded.\n",
      "Ntire2022 scene 62 is loaded.\n",
      "Ntire2022 scene 63 is loaded.\n",
      "Ntire2022 scene 64 is loaded.\n",
      "Ntire2022 scene 65 is loaded.\n",
      "Ntire2022 scene 66 is loaded.\n",
      "Ntire2022 scene 67 is loaded.\n",
      "Ntire2022 scene 68 is loaded.\n",
      "Ntire2022 scene 69 is loaded.\n",
      "Ntire2022 scene 70 is loaded.\n",
      "Ntire2022 scene 71 is loaded.\n",
      "Ntire2022 scene 72 is loaded.\n",
      "Ntire2022 scene 73 is loaded.\n",
      "Ntire2022 scene 74 is loaded.\n",
      "Ntire2022 scene 75 is loaded.\n",
      "Ntire2022 scene 76 is loaded.\n",
      "Ntire2022 scene 77 is loaded.\n",
      "Ntire2022 scene 78 is loaded.\n",
      "Ntire2022 scene 79 is loaded.\n",
      "Ntire2022 scene 80 is loaded.\n",
      "Ntire2022 scene 81 is loaded.\n",
      "Ntire2022 scene 82 is loaded.\n",
      "Ntire2022 scene 83 is loaded.\n",
      "Ntire2022 scene 84 is loaded.\n",
      "Ntire2022 scene 85 is loaded.\n",
      "Ntire2022 scene 86 is loaded.\n",
      "Ntire2022 scene 87 is loaded.\n",
      "Ntire2022 scene 88 is loaded.\n",
      "Ntire2022 scene 89 is loaded.\n",
      "Ntire2022 scene 90 is loaded.\n",
      "Ntire2022 scene 91 is loaded.\n",
      "Ntire2022 scene 92 is loaded.\n",
      "Ntire2022 scene 93 is loaded.\n",
      "Ntire2022 scene 94 is loaded.\n",
      "Ntire2022 scene 95 is loaded.\n",
      "Ntire2022 scene 96 is loaded.\n",
      "Ntire2022 scene 97 is loaded.\n",
      "Ntire2022 scene 98 is loaded.\n",
      "Ntire2022 scene 99 is loaded.\n",
      "Ntire2022 scene 100 is loaded.\n",
      "Ntire2022 scene 101 is loaded.\n",
      "Ntire2022 scene 102 is loaded.\n",
      "Ntire2022 scene 103 is loaded.\n",
      "Ntire2022 scene 104 is loaded.\n",
      "Ntire2022 scene 105 is loaded.\n",
      "Ntire2022 scene 106 is loaded.\n",
      "Ntire2022 scene 107 is loaded.\n",
      "Ntire2022 scene 108 is loaded.\n",
      "Ntire2022 scene 109 is loaded.\n",
      "Ntire2022 scene 110 is loaded.\n",
      "Ntire2022 scene 111 is loaded.\n",
      "Ntire2022 scene 112 is loaded.\n",
      "Ntire2022 scene 113 is loaded.\n",
      "Ntire2022 scene 114 is loaded.\n",
      "Ntire2022 scene 115 is loaded.\n",
      "Ntire2022 scene 116 is loaded.\n",
      "Ntire2022 scene 117 is loaded.\n",
      "Ntire2022 scene 118 is loaded.\n",
      "Ntire2022 scene 119 is loaded.\n",
      "Ntire2022 scene 120 is loaded.\n",
      "Ntire2022 scene 121 is loaded.\n",
      "Ntire2022 scene 122 is loaded.\n",
      "Ntire2022 scene 123 is loaded.\n",
      "Ntire2022 scene 124 is loaded.\n",
      "Ntire2022 scene 125 is loaded.\n",
      "Ntire2022 scene 126 is loaded.\n",
      "Ntire2022 scene 127 is loaded.\n",
      "Ntire2022 scene 128 is loaded.\n",
      "Ntire2022 scene 129 is loaded.\n",
      "Ntire2022 scene 130 is loaded.\n",
      "Ntire2022 scene 131 is loaded.\n",
      "Ntire2022 scene 132 is loaded.\n",
      "Ntire2022 scene 133 is loaded.\n",
      "Ntire2022 scene 134 is loaded.\n",
      "Ntire2022 scene 135 is loaded.\n",
      "Ntire2022 scene 136 is loaded.\n",
      "Ntire2022 scene 137 is loaded.\n",
      "Ntire2022 scene 138 is loaded.\n",
      "Ntire2022 scene 139 is loaded.\n",
      "Ntire2022 scene 140 is loaded.\n",
      "Ntire2022 scene 141 is loaded.\n",
      "Ntire2022 scene 142 is loaded.\n",
      "Ntire2022 scene 143 is loaded.\n",
      "Ntire2022 scene 144 is loaded.\n",
      "Ntire2022 scene 145 is loaded.\n",
      "Ntire2022 scene 146 is loaded.\n",
      "Ntire2022 scene 147 is loaded.\n",
      "Ntire2022 scene 148 is loaded.\n",
      "Ntire2022 scene 149 is loaded.\n",
      "Ntire2022 scene 150 is loaded.\n",
      "Ntire2022 scene 151 is loaded.\n",
      "Ntire2022 scene 152 is loaded.\n",
      "Ntire2022 scene 153 is loaded.\n",
      "Ntire2022 scene 154 is loaded.\n",
      "Ntire2022 scene 155 is loaded.\n",
      "Ntire2022 scene 156 is loaded.\n",
      "Ntire2022 scene 157 is loaded.\n",
      "Ntire2022 scene 158 is loaded.\n",
      "Ntire2022 scene 159 is loaded.\n",
      "Ntire2022 scene 160 is loaded.\n",
      "Ntire2022 scene 161 is loaded.\n",
      "Ntire2022 scene 162 is loaded.\n",
      "Ntire2022 scene 163 is loaded.\n",
      "Ntire2022 scene 164 is loaded.\n",
      "Ntire2022 scene 165 is loaded.\n",
      "Ntire2022 scene 166 is loaded.\n",
      "Ntire2022 scene 167 is loaded.\n",
      "Ntire2022 scene 168 is loaded.\n",
      "Ntire2022 scene 169 is loaded.\n",
      "Ntire2022 scene 170 is loaded.\n",
      "Ntire2022 scene 171 is loaded.\n",
      "Ntire2022 scene 172 is loaded.\n",
      "Ntire2022 scene 173 is loaded.\n",
      "Ntire2022 scene 174 is loaded.\n",
      "Ntire2022 scene 175 is loaded.\n",
      "Ntire2022 scene 176 is loaded.\n",
      "Ntire2022 scene 177 is loaded.\n",
      "Ntire2022 scene 178 is loaded.\n",
      "Ntire2022 scene 179 is loaded.\n",
      "Ntire2022 scene 180 is loaded.\n",
      "Ntire2022 scene 181 is loaded.\n",
      "Ntire2022 scene 182 is loaded.\n",
      "Ntire2022 scene 183 is loaded.\n",
      "Ntire2022 scene 184 is loaded.\n",
      "Ntire2022 scene 185 is loaded.\n",
      "Ntire2022 scene 186 is loaded.\n",
      "Ntire2022 scene 187 is loaded.\n",
      "Ntire2022 scene 188 is loaded.\n",
      "Ntire2022 scene 189 is loaded.\n",
      "Ntire2022 scene 190 is loaded.\n",
      "Ntire2022 scene 191 is loaded.\n",
      "Ntire2022 scene 192 is loaded.\n",
      "Ntire2022 scene 193 is loaded.\n",
      "Ntire2022 scene 194 is loaded.\n",
      "Ntire2022 scene 195 is loaded.\n",
      "Ntire2022 scene 196 is loaded.\n",
      "Ntire2022 scene 197 is loaded.\n",
      "Ntire2022 scene 198 is loaded.\n",
      "Ntire2022 scene 199 is loaded.\n",
      "Ntire2022 scene 200 is loaded.\n",
      "Ntire2022 scene 201 is loaded.\n",
      "Ntire2022 scene 202 is loaded.\n",
      "Ntire2022 scene 203 is loaded.\n",
      "Ntire2022 scene 204 is loaded.\n",
      "Ntire2022 scene 205 is loaded.\n",
      "Ntire2022 scene 206 is loaded.\n",
      "Ntire2022 scene 207 is loaded.\n",
      "Ntire2022 scene 208 is loaded.\n",
      "Ntire2022 scene 209 is loaded.\n",
      "Ntire2022 scene 210 is loaded.\n",
      "Ntire2022 scene 211 is loaded.\n",
      "Ntire2022 scene 212 is loaded.\n",
      "Ntire2022 scene 213 is loaded.\n",
      "Ntire2022 scene 214 is loaded.\n",
      "Ntire2022 scene 215 is loaded.\n",
      "Ntire2022 scene 216 is loaded.\n",
      "Ntire2022 scene 217 is loaded.\n",
      "Ntire2022 scene 218 is loaded.\n",
      "Ntire2022 scene 219 is loaded.\n",
      "Ntire2022 scene 220 is loaded.\n",
      "Ntire2022 scene 221 is loaded.\n",
      "Ntire2022 scene 222 is loaded.\n",
      "Ntire2022 scene 223 is loaded.\n",
      "Ntire2022 scene 224 is loaded.\n",
      "Ntire2022 scene 225 is loaded.\n",
      "Ntire2022 scene 226 is loaded.\n",
      "Ntire2022 scene 227 is loaded.\n",
      "Ntire2022 scene 228 is loaded.\n",
      "Ntire2022 scene 229 is loaded.\n",
      "Ntire2022 scene 230 is loaded.\n",
      "Ntire2022 scene 231 is loaded.\n",
      "Ntire2022 scene 232 is loaded.\n",
      "Ntire2022 scene 233 is loaded.\n",
      "Ntire2022 scene 234 is loaded.\n",
      "Ntire2022 scene 235 is loaded.\n",
      "Ntire2022 scene 236 is loaded.\n",
      "Ntire2022 scene 237 is loaded.\n",
      "Ntire2022 scene 238 is loaded.\n",
      "Ntire2022 scene 239 is loaded.\n",
      "Ntire2022 scene 240 is loaded.\n",
      "Ntire2022 scene 241 is loaded.\n",
      "Ntire2022 scene 242 is loaded.\n",
      "Ntire2022 scene 243 is loaded.\n",
      "Ntire2022 scene 244 is loaded.\n",
      "Ntire2022 scene 245 is loaded.\n",
      "Ntire2022 scene 246 is loaded.\n",
      "Ntire2022 scene 247 is loaded.\n",
      "Ntire2022 scene 248 is loaded.\n",
      "Ntire2022 scene 249 is loaded.\n",
      "Ntire2022 scene 250 is loaded.\n",
      "Ntire2022 scene 251 is loaded.\n",
      "Ntire2022 scene 252 is loaded.\n",
      "Ntire2022 scene 253 is loaded.\n",
      "Ntire2022 scene 254 is loaded.\n",
      "Ntire2022 scene 255 is loaded.\n",
      "Ntire2022 scene 256 is loaded.\n",
      "Ntire2022 scene 257 is loaded.\n",
      "Ntire2022 scene 258 is loaded.\n",
      "Ntire2022 scene 259 is loaded.\n",
      "Ntire2022 scene 260 is loaded.\n",
      "Ntire2022 scene 261 is loaded.\n",
      "Ntire2022 scene 262 is loaded.\n",
      "Ntire2022 scene 263 is loaded.\n",
      "Ntire2022 scene 264 is loaded.\n",
      "Ntire2022 scene 265 is loaded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ntire2022 scene 266 is loaded.\n",
      "Ntire2022 scene 267 is loaded.\n",
      "Ntire2022 scene 268 is loaded.\n",
      "Ntire2022 scene 269 is loaded.\n",
      "Ntire2022 scene 270 is loaded.\n",
      "Ntire2022 scene 271 is loaded.\n",
      "Ntire2022 scene 272 is loaded.\n",
      "Ntire2022 scene 273 is loaded.\n",
      "Ntire2022 scene 274 is loaded.\n",
      "Ntire2022 scene 275 is loaded.\n",
      "Ntire2022 scene 276 is loaded.\n",
      "Ntire2022 scene 277 is loaded.\n",
      "Ntire2022 scene 278 is loaded.\n",
      "Ntire2022 scene 279 is loaded.\n",
      "Ntire2022 scene 280 is loaded.\n",
      "Ntire2022 scene 281 is loaded.\n",
      "Ntire2022 scene 282 is loaded.\n",
      "Ntire2022 scene 283 is loaded.\n",
      "Ntire2022 scene 284 is loaded.\n",
      "Ntire2022 scene 285 is loaded.\n",
      "Ntire2022 scene 286 is loaded.\n",
      "Ntire2022 scene 287 is loaded.\n",
      "Ntire2022 scene 288 is loaded.\n",
      "Ntire2022 scene 289 is loaded.\n",
      "Ntire2022 scene 290 is loaded.\n",
      "Ntire2022 scene 291 is loaded.\n",
      "Ntire2022 scene 292 is loaded.\n",
      "Ntire2022 scene 293 is loaded.\n",
      "Ntire2022 scene 294 is loaded.\n",
      "Ntire2022 scene 295 is loaded.\n",
      "Ntire2022 scene 296 is loaded.\n",
      "Ntire2022 scene 297 is loaded.\n",
      "Ntire2022 scene 298 is loaded.\n",
      "Ntire2022 scene 299 is loaded.\n",
      "Ntire2022 scene 300 is loaded.\n",
      "Ntire2022 scene 301 is loaded.\n",
      "Ntire2022 scene 302 is loaded.\n",
      "Ntire2022 scene 303 is loaded.\n",
      "Ntire2022 scene 304 is loaded.\n",
      "Ntire2022 scene 305 is loaded.\n",
      "Ntire2022 scene 306 is loaded.\n",
      "Ntire2022 scene 307 is loaded.\n",
      "Ntire2022 scene 308 is loaded.\n",
      "Ntire2022 scene 309 is loaded.\n",
      "Ntire2022 scene 310 is loaded.\n",
      "Ntire2022 scene 311 is loaded.\n",
      "Ntire2022 scene 312 is loaded.\n",
      "Ntire2022 scene 313 is loaded.\n",
      "Ntire2022 scene 314 is loaded.\n",
      "Ntire2022 scene 315 is loaded.\n",
      "Ntire2022 scene 316 is loaded.\n",
      "Ntire2022 scene 317 is loaded.\n",
      "Ntire2022 scene 318 is loaded.\n",
      "Ntire2022 scene 319 is loaded.\n",
      "Ntire2022 scene 320 is loaded.\n",
      "Ntire2022 scene 321 is loaded.\n",
      "Ntire2022 scene 322 is loaded.\n",
      "Ntire2022 scene 323 is loaded.\n",
      "Ntire2022 scene 324 is loaded.\n",
      "Ntire2022 scene 325 is loaded.\n",
      "Ntire2022 scene 326 is loaded.\n",
      "Ntire2022 scene 327 is loaded.\n",
      "Ntire2022 scene 328 is loaded.\n",
      "Ntire2022 scene 329 is loaded.\n",
      "Ntire2022 scene 330 is loaded.\n",
      "Ntire2022 scene 331 is loaded.\n",
      "Ntire2022 scene 332 is loaded.\n",
      "Ntire2022 scene 333 is loaded.\n",
      "Ntire2022 scene 334 is loaded.\n",
      "Ntire2022 scene 335 is loaded.\n",
      "Ntire2022 scene 336 is loaded.\n",
      "Ntire2022 scene 337 is loaded.\n",
      "Ntire2022 scene 338 is loaded.\n",
      "Ntire2022 scene 339 is loaded.\n",
      "Ntire2022 scene 340 is loaded.\n",
      "Ntire2022 scene 341 is loaded.\n",
      "Ntire2022 scene 342 is loaded.\n",
      "Ntire2022 scene 343 is loaded.\n",
      "Ntire2022 scene 344 is loaded.\n",
      "Ntire2022 scene 345 is loaded.\n",
      "Ntire2022 scene 346 is loaded.\n",
      "Ntire2022 scene 347 is loaded.\n",
      "Ntire2022 scene 348 is loaded.\n",
      "Ntire2022 scene 349 is loaded.\n",
      "Ntire2022 scene 350 is loaded.\n",
      "Ntire2022 scene 351 is loaded.\n",
      "Ntire2022 scene 352 is loaded.\n",
      "Ntire2022 scene 353 is loaded.\n",
      "Ntire2022 scene 354 is loaded.\n",
      "Ntire2022 scene 355 is loaded.\n",
      "Ntire2022 scene 356 is loaded.\n",
      "Ntire2022 scene 357 is loaded.\n",
      "Ntire2022 scene 358 is loaded.\n",
      "Ntire2022 scene 359 is loaded.\n",
      "Ntire2022 scene 360 is loaded.\n",
      "Ntire2022 scene 361 is loaded.\n",
      "Ntire2022 scene 362 is loaded.\n",
      "Ntire2022 scene 363 is loaded.\n",
      "Ntire2022 scene 364 is loaded.\n",
      "Ntire2022 scene 365 is loaded.\n",
      "Ntire2022 scene 366 is loaded.\n",
      "Ntire2022 scene 367 is loaded.\n",
      "Ntire2022 scene 368 is loaded.\n",
      "Ntire2022 scene 369 is loaded.\n",
      "Ntire2022 scene 370 is loaded.\n",
      "Ntire2022 scene 371 is loaded.\n",
      "Ntire2022 scene 372 is loaded.\n",
      "Ntire2022 scene 373 is loaded.\n",
      "Ntire2022 scene 374 is loaded.\n",
      "Ntire2022 scene 375 is loaded.\n",
      "Ntire2022 scene 376 is loaded.\n",
      "Ntire2022 scene 377 is loaded.\n",
      "Ntire2022 scene 378 is loaded.\n",
      "Ntire2022 scene 379 is loaded.\n",
      "Ntire2022 scene 380 is loaded.\n",
      "Ntire2022 scene 381 is loaded.\n",
      "Ntire2022 scene 382 is loaded.\n",
      "Ntire2022 scene 383 is loaded.\n",
      "Ntire2022 scene 384 is loaded.\n",
      "Ntire2022 scene 385 is loaded.\n",
      "Ntire2022 scene 386 is loaded.\n",
      "Ntire2022 scene 387 is loaded.\n",
      "Ntire2022 scene 388 is loaded.\n",
      "Ntire2022 scene 389 is loaded.\n",
      "Ntire2022 scene 390 is loaded.\n",
      "Ntire2022 scene 391 is loaded.\n",
      "Ntire2022 scene 392 is loaded.\n",
      "Ntire2022 scene 393 is loaded.\n",
      "Ntire2022 scene 394 is loaded.\n",
      "Ntire2022 scene 395 is loaded.\n",
      "Ntire2022 scene 396 is loaded.\n",
      "Ntire2022 scene 397 is loaded.\n",
      "Ntire2022 scene 398 is loaded.\n",
      "Ntire2022 scene 399 is loaded.\n",
      "Ntire2022 scene 400 is loaded.\n",
      "Ntire2022 scene 401 is loaded.\n",
      "Ntire2022 scene 402 is loaded.\n",
      "Ntire2022 scene 403 is loaded.\n",
      "Ntire2022 scene 404 is loaded.\n",
      "Ntire2022 scene 405 is loaded.\n",
      "Ntire2022 scene 406 is loaded.\n",
      "Ntire2022 scene 407 is loaded.\n",
      "Ntire2022 scene 408 is loaded.\n",
      "Ntire2022 scene 409 is loaded.\n",
      "Ntire2022 scene 410 is loaded.\n",
      "Ntire2022 scene 411 is loaded.\n",
      "Ntire2022 scene 412 is loaded.\n",
      "Ntire2022 scene 413 is loaded.\n",
      "Ntire2022 scene 414 is loaded.\n",
      "Ntire2022 scene 415 is loaded.\n",
      "Ntire2022 scene 416 is loaded.\n",
      "Ntire2022 scene 417 is loaded.\n",
      "Ntire2022 scene 418 is loaded.\n",
      "Ntire2022 scene 419 is loaded.\n",
      "Ntire2022 scene 420 is loaded.\n",
      "Ntire2022 scene 421 is loaded.\n",
      "Ntire2022 scene 422 is loaded.\n",
      "Ntire2022 scene 423 is loaded.\n",
      "Ntire2022 scene 424 is loaded.\n",
      "Ntire2022 scene 425 is loaded.\n",
      "Ntire2022 scene 426 is loaded.\n",
      "Ntire2022 scene 427 is loaded.\n",
      "Ntire2022 scene 428 is loaded.\n",
      "Ntire2022 scene 429 is loaded.\n",
      "Ntire2022 scene 430 is loaded.\n",
      "Ntire2022 scene 431 is loaded.\n",
      "Ntire2022 scene 432 is loaded.\n",
      "Ntire2022 scene 433 is loaded.\n",
      "Ntire2022 scene 434 is loaded.\n",
      "Ntire2022 scene 435 is loaded.\n",
      "Ntire2022 scene 436 is loaded.\n",
      "Ntire2022 scene 437 is loaded.\n",
      "Ntire2022 scene 438 is loaded.\n",
      "Ntire2022 scene 439 is loaded.\n",
      "Ntire2022 scene 440 is loaded.\n",
      "Ntire2022 scene 441 is loaded.\n",
      "Ntire2022 scene 442 is loaded.\n",
      "Ntire2022 scene 443 is loaded.\n",
      "Ntire2022 scene 444 is loaded.\n",
      "Ntire2022 scene 445 is loaded.\n",
      "Ntire2022 scene 446 is loaded.\n",
      "Ntire2022 scene 447 is loaded.\n",
      "Ntire2022 scene 448 is loaded.\n",
      "Ntire2022 scene 449 is loaded.\n",
      "Ntire2022 scene 450 is loaded.\n",
      "Ntire2022 scene 451 is loaded.\n",
      "Ntire2022 scene 452 is loaded.\n",
      "Ntire2022 scene 453 is loaded.\n",
      "Ntire2022 scene 454 is loaded.\n",
      "Ntire2022 scene 455 is loaded.\n",
      "Ntire2022 scene 456 is loaded.\n",
      "Ntire2022 scene 457 is loaded.\n",
      "Ntire2022 scene 458 is loaded.\n",
      "Ntire2022 scene 459 is loaded.\n",
      "Ntire2022 scene 460 is loaded.\n",
      "Ntire2022 scene 461 is loaded.\n",
      "Ntire2022 scene 462 is loaded.\n",
      "Ntire2022 scene 463 is loaded.\n",
      "Ntire2022 scene 464 is loaded.\n",
      "Ntire2022 scene 465 is loaded.\n",
      "Ntire2022 scene 466 is loaded.\n",
      "Ntire2022 scene 467 is loaded.\n",
      "Ntire2022 scene 468 is loaded.\n",
      "Ntire2022 scene 469 is loaded.\n",
      "Ntire2022 scene 470 is loaded.\n",
      "Ntire2022 scene 471 is loaded.\n",
      "Ntire2022 scene 472 is loaded.\n",
      "Ntire2022 scene 473 is loaded.\n",
      "Ntire2022 scene 474 is loaded.\n",
      "Ntire2022 scene 475 is loaded.\n",
      "Ntire2022 scene 476 is loaded.\n",
      "Ntire2022 scene 477 is loaded.\n",
      "Ntire2022 scene 478 is loaded.\n",
      "Ntire2022 scene 479 is loaded.\n",
      "Ntire2022 scene 480 is loaded.\n",
      "Ntire2022 scene 481 is loaded.\n",
      "Ntire2022 scene 482 is loaded.\n",
      "Ntire2022 scene 483 is loaded.\n",
      "Ntire2022 scene 484 is loaded.\n",
      "Ntire2022 scene 485 is loaded.\n",
      "Ntire2022 scene 486 is loaded.\n",
      "Ntire2022 scene 487 is loaded.\n",
      "Ntire2022 scene 488 is loaded.\n",
      "Ntire2022 scene 489 is loaded.\n",
      "Ntire2022 scene 490 is loaded.\n",
      "Ntire2022 scene 491 is loaded.\n",
      "Ntire2022 scene 492 is loaded.\n",
      "Ntire2022 scene 493 is loaded.\n",
      "Ntire2022 scene 494 is loaded.\n",
      "Ntire2022 scene 495 is loaded.\n",
      "Ntire2022 scene 496 is loaded.\n",
      "Ntire2022 scene 497 is loaded.\n",
      "Ntire2022 scene 498 is loaded.\n",
      "Ntire2022 scene 499 is loaded.\n",
      "Ntire2022 scene 500 is loaded.\n",
      "Ntire2022 scene 501 is loaded.\n",
      "Ntire2022 scene 502 is loaded.\n",
      "Ntire2022 scene 503 is loaded.\n",
      "Ntire2022 scene 504 is loaded.\n",
      "Ntire2022 scene 505 is loaded.\n",
      "Ntire2022 scene 506 is loaded.\n",
      "Ntire2022 scene 507 is loaded.\n",
      "Ntire2022 scene 508 is loaded.\n",
      "Ntire2022 scene 509 is loaded.\n",
      "Ntire2022 scene 510 is loaded.\n",
      "Ntire2022 scene 511 is loaded.\n",
      "Ntire2022 scene 512 is loaded.\n",
      "Ntire2022 scene 513 is loaded.\n",
      "Ntire2022 scene 514 is loaded.\n",
      "Ntire2022 scene 515 is loaded.\n",
      "Ntire2022 scene 516 is loaded.\n",
      "Ntire2022 scene 517 is loaded.\n",
      "Ntire2022 scene 518 is loaded.\n",
      "Ntire2022 scene 519 is loaded.\n",
      "Ntire2022 scene 520 is loaded.\n",
      "Ntire2022 scene 521 is loaded.\n",
      "Ntire2022 scene 522 is loaded.\n",
      "Ntire2022 scene 523 is loaded.\n",
      "Ntire2022 scene 524 is loaded.\n",
      "Ntire2022 scene 525 is loaded.\n",
      "Ntire2022 scene 526 is loaded.\n",
      "Ntire2022 scene 527 is loaded.\n",
      "Ntire2022 scene 528 is loaded.\n",
      "Ntire2022 scene 529 is loaded.\n",
      "Ntire2022 scene 530 is loaded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ntire2022 scene 531 is loaded.\n",
      "Ntire2022 scene 532 is loaded.\n",
      "Ntire2022 scene 533 is loaded.\n",
      "Ntire2022 scene 534 is loaded.\n",
      "Ntire2022 scene 535 is loaded.\n",
      "Ntire2022 scene 536 is loaded.\n",
      "Ntire2022 scene 537 is loaded.\n",
      "Ntire2022 scene 538 is loaded.\n",
      "Ntire2022 scene 539 is loaded.\n",
      "Ntire2022 scene 540 is loaded.\n",
      "Ntire2022 scene 541 is loaded.\n",
      "Ntire2022 scene 542 is loaded.\n",
      "Ntire2022 scene 543 is loaded.\n",
      "Ntire2022 scene 544 is loaded.\n",
      "Ntire2022 scene 545 is loaded.\n",
      "Ntire2022 scene 546 is loaded.\n",
      "Ntire2022 scene 547 is loaded.\n",
      "Ntire2022 scene 548 is loaded.\n",
      "Ntire2022 scene 549 is loaded.\n",
      "Ntire2022 scene 550 is loaded.\n",
      "Ntire2022 scene 551 is loaded.\n",
      "Ntire2022 scene 552 is loaded.\n",
      "Ntire2022 scene 553 is loaded.\n",
      "Ntire2022 scene 554 is loaded.\n",
      "Ntire2022 scene 555 is loaded.\n",
      "Ntire2022 scene 556 is loaded.\n",
      "Ntire2022 scene 557 is loaded.\n",
      "Ntire2022 scene 558 is loaded.\n",
      "Ntire2022 scene 559 is loaded.\n",
      "Ntire2022 scene 560 is loaded.\n",
      "Ntire2022 scene 561 is loaded.\n",
      "Ntire2022 scene 562 is loaded.\n",
      "Ntire2022 scene 563 is loaded.\n",
      "Ntire2022 scene 564 is loaded.\n",
      "Ntire2022 scene 565 is loaded.\n",
      "Ntire2022 scene 566 is loaded.\n",
      "Ntire2022 scene 567 is loaded.\n",
      "Ntire2022 scene 568 is loaded.\n",
      "Ntire2022 scene 569 is loaded.\n",
      "Ntire2022 scene 570 is loaded.\n",
      "Ntire2022 scene 571 is loaded.\n",
      "Ntire2022 scene 572 is loaded.\n",
      "Ntire2022 scene 573 is loaded.\n",
      "Ntire2022 scene 574 is loaded.\n",
      "Ntire2022 scene 575 is loaded.\n",
      "Ntire2022 scene 576 is loaded.\n",
      "Ntire2022 scene 577 is loaded.\n",
      "Ntire2022 scene 578 is loaded.\n",
      "Ntire2022 scene 579 is loaded.\n",
      "Ntire2022 scene 580 is loaded.\n",
      "Ntire2022 scene 581 is loaded.\n",
      "Ntire2022 scene 582 is loaded.\n",
      "Ntire2022 scene 583 is loaded.\n",
      "Ntire2022 scene 584 is loaded.\n",
      "Ntire2022 scene 585 is loaded.\n",
      "Ntire2022 scene 586 is loaded.\n",
      "Ntire2022 scene 587 is loaded.\n",
      "Ntire2022 scene 588 is loaded.\n",
      "Ntire2022 scene 589 is loaded.\n",
      "Ntire2022 scene 590 is loaded.\n",
      "Ntire2022 scene 591 is loaded.\n",
      "Ntire2022 scene 592 is loaded.\n",
      "Ntire2022 scene 593 is loaded.\n",
      "Ntire2022 scene 594 is loaded.\n",
      "Ntire2022 scene 595 is loaded.\n",
      "Ntire2022 scene 596 is loaded.\n",
      "Ntire2022 scene 597 is loaded.\n",
      "Ntire2022 scene 598 is loaded.\n",
      "Ntire2022 scene 599 is loaded.\n",
      "Ntire2022 scene 600 is loaded.\n",
      "Ntire2022 scene 601 is loaded.\n",
      "Ntire2022 scene 602 is loaded.\n",
      "Ntire2022 scene 603 is loaded.\n",
      "Ntire2022 scene 604 is loaded.\n",
      "Ntire2022 scene 605 is loaded.\n",
      "Ntire2022 scene 606 is loaded.\n",
      "Ntire2022 scene 607 is loaded.\n",
      "Ntire2022 scene 608 is loaded.\n",
      "Ntire2022 scene 609 is loaded.\n",
      "Ntire2022 scene 610 is loaded.\n",
      "Ntire2022 scene 611 is loaded.\n",
      "Ntire2022 scene 612 is loaded.\n",
      "Ntire2022 scene 613 is loaded.\n",
      "Ntire2022 scene 614 is loaded.\n",
      "Ntire2022 scene 615 is loaded.\n",
      "Ntire2022 scene 616 is loaded.\n",
      "Ntire2022 scene 617 is loaded.\n",
      "Ntire2022 scene 618 is loaded.\n",
      "Ntire2022 scene 619 is loaded.\n",
      "Ntire2022 scene 620 is loaded.\n",
      "Ntire2022 scene 621 is loaded.\n",
      "Ntire2022 scene 622 is loaded.\n",
      "Ntire2022 scene 623 is loaded.\n",
      "Ntire2022 scene 624 is loaded.\n",
      "Ntire2022 scene 625 is loaded.\n",
      "Ntire2022 scene 626 is loaded.\n",
      "Ntire2022 scene 627 is loaded.\n",
      "Ntire2022 scene 628 is loaded.\n",
      "Ntire2022 scene 629 is loaded.\n",
      "Ntire2022 scene 630 is loaded.\n",
      "Ntire2022 scene 631 is loaded.\n",
      "Ntire2022 scene 632 is loaded.\n",
      "Ntire2022 scene 633 is loaded.\n",
      "Ntire2022 scene 634 is loaded.\n",
      "Ntire2022 scene 635 is loaded.\n",
      "Ntire2022 scene 636 is loaded.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the dataset path\n",
    "data_root = \"C:/Users/user/Desktop/Research/Datasets/Manual_split_NTIRE_2022\"\n",
    "\n",
    "# Create instances of TrainDataset and ValidDataset\n",
    "train_dataset = TrainDataset(data_root=data_root, bgr2rgb=True)\n",
    "valid_dataset = ValidDataset(data_root=data_root, bgr2rgb=True)\n",
    "\n",
    "# Create DataLoader instances for both datasets\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=1, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Load one batch of data from each DataLoader\n",
    "train_images, train_labels = next(iter(train_loader))\n",
    "valid_images, valid_labels = next(iter(valid_loader))\n",
    "\n",
    "# Print the shapes of the loaded data\n",
    "print(\"Train Images Shape:\", train_images.shape)\n",
    "print(\"Train Labels Shape:\", train_labels.shape)\n",
    "print(\"Valid Images Shape:\", valid_images.shape)\n",
    "print(\"Valid Labels Shape:\", valid_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(valid_loader))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample = train_dataset[0]\n",
    "x, y = sample[0], sample[1]\n",
    "\n",
    "# Create subplots for the 3-channel input (RGB)\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(x.shape[0]):  # Loop through channels\n",
    "    plt.subplot(1, 3, i + 1)  # Adjust for the number of input channels (3)\n",
    "    channel_data = x[i]\n",
    "    plt.imshow(channel_data, cmap='gray')  # Display each channel in grayscale\n",
    "    plt.title(f'Input Channel {i + 1}')\n",
    "    plt.axis('off')\n",
    "\n",
    "# Create subplots for the 31-channel output (Hyperspectral)\n",
    "plt.figure(figsize=(18, 18))  # Adjust size as needed\n",
    "for i in range(y.shape[0]):  # Loop through channels\n",
    "    plt.subplot(6, 6, i + 1)  # Adjust subplot grid for 31 channels\n",
    "    channel_data = y[i]\n",
    "    plt.imshow(channel_data, cmap='gray')  # Display each channel in grayscale\n",
    "    plt.title(f'Output Channel {i + 1}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## custom SAM LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SAMLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SAMLoss, self).__init__()\n",
    "\n",
    "    def forward(self, predicted_hsi, ground_truth_hsi):\n",
    "        # Ensure the input tensors have the same shape\n",
    "        assert predicted_hsi.shape == ground_truth_hsi.shape, \"Input tensor shapes must match.\"\n",
    "\n",
    "        # Reshape tensors if necessary\n",
    "        if predicted_hsi.dim() == 4:  # If the tensors are 4D, flatten them\n",
    "            predicted_hsi = predicted_hsi.view(predicted_hsi.size(0), -1)\n",
    "            ground_truth_hsi = ground_truth_hsi.view(ground_truth_hsi.size(0), -1)\n",
    "\n",
    "        # Calculate the dot product and magnitudes\n",
    "        dot_product = torch.sum(predicted_hsi * ground_truth_hsi, dim=1)\n",
    "        magnitude_pred = torch.norm(predicted_hsi, dim=1)\n",
    "        magnitude_gt = torch.norm(ground_truth_hsi, dim=1)\n",
    "\n",
    "        # Calculate the cosine of the spectral angle\n",
    "        cosine_theta = dot_product / (magnitude_pred * magnitude_gt)\n",
    "\n",
    "        # Calculate the spectral angle in radians\n",
    "        spectral_angle = torch.acos(cosine_theta)\n",
    "\n",
    "        # Return the mean spectral angle as the loss\n",
    "        return torch.mean(spectral_angle)\n",
    "    \n",
    "class Loss_MRAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Loss_MRAE, self).__init__()\n",
    "\n",
    "    def forward(self, outputs, label):\n",
    "        assert outputs.shape == label.shape\n",
    "        error = torch.abs(outputs - label) / label\n",
    "        mrae = torch.mean(error.view(-1))\n",
    "        return mrae\n",
    "\n",
    "class Loss_RMSE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Loss_RMSE, self).__init__()\n",
    "\n",
    "    def forward(self, outputs, label):\n",
    "        assert outputs.shape == label.shape\n",
    "        error = outputs-label\n",
    "        sqrt_error = torch.pow(error,2)\n",
    "        rmse = torch.sqrt(torch.mean(sqrt_error.view(-1)))\n",
    "        return rmse\n",
    "\n",
    "class Loss_PSNR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Loss_PSNR, self).__init__()\n",
    "\n",
    "    def forward(self, im_true, im_fake, data_range=255):\n",
    "        N = im_true.size()[0]\n",
    "        C = im_true.size()[1]\n",
    "        H = im_true.size()[2]\n",
    "        W = im_true.size()[3]\n",
    "        Itrue = im_true.clamp(0., 1.).mul_(data_range).resize_(N, C * H * W)\n",
    "        Ifake = im_fake.clamp(0., 1.).mul_(data_range).resize_(N, C * H * W)\n",
    "        mse = nn.MSELoss(reduce=False)\n",
    "        err = mse(Itrue, Ifake).sum(dim=1, keepdim=True).div_(C * H * W)\n",
    "        psnr = 10. * torch.log((data_range ** 2) / err) / np.log(10.)\n",
    "        return torch.mean(psnr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combined loss L1loss and SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, beta=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.l1_loss = nn.L1Loss()\n",
    "        self.sam_loss = SAMLoss()\n",
    "\n",
    "    def forward(self, outputs, labels):\n",
    "        loss_l1 = self.l1_loss(outputs, labels)\n",
    "        loss_sam = self.sam_loss(outputs, labels)\n",
    "        combined_loss = self.alpha * loss_l1 + self.beta * loss_sam\n",
    "        return combined_loss\n",
    "    \n",
    "class SRLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, beta=0.5):\n",
    "        super(SRLoss, self).__init__()\n",
    "        self.alpha = alpha  # Weight for SAM loss\n",
    "        self.beta = beta    # Weight for RMSE loss\n",
    "\n",
    "        # Define the SAM and RMSE loss functions\n",
    "        self.sam_loss = SAMLoss()\n",
    "        self.rmse_loss = Loss_RMSE()\n",
    "\n",
    "    def forward(self, outputs, labels):\n",
    "        # Calculate the SAM loss\n",
    "        sam_loss = self.sam_loss(outputs, labels)\n",
    "\n",
    "        # Calculate the RMSE loss\n",
    "        rmse_loss = self.rmse_loss(outputs, labels)\n",
    "\n",
    "        # Combine the SAM and RMSE losses using weights (alpha and beta)\n",
    "        combined_loss = self.alpha * sam_loss + self.beta * rmse_loss\n",
    "\n",
    "        return combined_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperAttention model with spacial, spectral attention and fft block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import GradScaler, autocast  \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class SpectralAttention(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(SpectralAttention, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 1, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_pool = F.avg_pool2d(x, (x.size(2), x.size(3)))\n",
    "        channel_weights = self.sigmoid(self.conv1(avg_pool))\n",
    "        x_att = x * channel_weights\n",
    "        return x_att\n",
    "\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 1, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.batch_norm = nn.BatchNorm2d(in_channels)  # Batch Normalization\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm(x)  # Apply Batch Normalization\n",
    "        spatial_weights = self.sigmoid(self.conv1(x))\n",
    "        x_att = x * spatial_weights\n",
    "        return x_att\n",
    "    \n",
    "class OutputNormalization(nn.Module):\n",
    "    def forward(self, x):\n",
    "        min_val = torch.min(x)\n",
    "        range_val = torch.max(x) - min_val\n",
    "        return (x - min_val) / (range_val + 1e-8)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.spacial_enc1 = SpatialAttention(64)\n",
    "        self.spectral_enc1 = SpectralAttention(64)\n",
    "        \n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.spacial_enc2 = SpatialAttention(128)\n",
    "        self.spectral_enc2 = SpectralAttention(128)\n",
    "        \n",
    "        self.enc3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.spacial_enc3 = SpatialAttention(256)\n",
    "        self.spectral_enc3 = SpectralAttention(256)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.spacial_bot = SpatialAttention(256)\n",
    "        self.spectral_bot = SpectralAttention(256)\n",
    "\n",
    "        # Decoder\n",
    "        self.dec1 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(128, 128, kernel_size=2, stride=2)  # Upsampling\n",
    "        )\n",
    "        \n",
    "        self.spacial_dec1 = SpatialAttention(128)\n",
    "        self.spectral_dec1 = SpectralAttention(128)\n",
    "        \n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            SpectralAttention(128),  # Spectral attention mechanism\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2)  # Upsampling\n",
    "        )\n",
    "        \n",
    "        self.spacial_dec2 = SpatialAttention(64)\n",
    "        self.spectral_dec2 = SpectralAttention(64)\n",
    "        \n",
    "        self.output_norm = OutputNormalization()\n",
    "        \n",
    "        self.dec3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(64, out_channels, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1 = self.enc1(x)\n",
    "#         print(enc1.shape)\n",
    "        enc2 = self.enc2(enc1)\n",
    "#         print(enc2.shape)\n",
    "        enc3 = self.enc3(enc2)\n",
    "#         print(enc3.shape)\n",
    "\n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck(enc3)\n",
    "#         print(bottleneck.shape)\n",
    "\n",
    "        # Decoder\n",
    "        dec1 = self.dec1(torch.cat([enc3, bottleneck], dim=1))\n",
    "#         print(dec1.shape)\n",
    "        dec2 = self.dec2(torch.cat([enc2, dec1], dim=1))\n",
    "#         print(dec2.shape)\n",
    "        enc1 = self.spacial_enc1(enc1)\n",
    "    \n",
    "        dec3 = self.dec3(torch.cat([enc1, dec2], dim=1))\n",
    "#         print(dec3.shape)\n",
    "        dec3 = self.output_norm(dec3)\n",
    "    \n",
    "        return dec3\n",
    "    \n",
    "    def adjust_channels(self, x, target_channels):\n",
    "        if x.size(1) == target_channels:\n",
    "            return x\n",
    "        else:\n",
    "            # Move the convolutional layer to the same device as the input tensor\n",
    "            conv_layer = nn.Conv2d(x.size(1), target_channels, kernel_size=1).to(x.device)\n",
    "            return conv_layer(x)\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initialize the U-Net model with skip connections, loss function, and optimizer\n",
    "model= UNet(in_channels=3, out_channels=31).to(device).float()\n",
    "model = model.float()\n",
    "# criterion = nn.L1Loss()  # You can use a suitable loss function for your task\n",
    "criterion =SAMLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Model, criterion, and other components initialization code remains the same\n",
    "\n",
    "# Lists to store losses for plotting\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "verbose_logs = []\n",
    "\n",
    "# Set hyperparameters\n",
    "batch_size = 1\n",
    "learning_rate = 0.001  # Define the learning rate before the optimizer\n",
    "num_epochs = 2000  # Number of epochs\n",
    "checkpoint_interval = 200\n",
    "\n",
    "# Initialize the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HyperAttention(in_channels=3, out_channels=31).to(device).float()\n",
    "\n",
    "# Initialize optimizer with beta parameters\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(beta1, beta2))\n",
    "\n",
    "# Define and initialize the cosine annealing scheduler\n",
    "T_max = 60  # The number of epochs for cosine annealing\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max)\n",
    "# criterion = SAMLoss()\n",
    "criterion = SRLoss()\n",
    "\n",
    "# Training and validation functions remain the same\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_model_epoch = 0\n",
    "\n",
    "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "# Function to validate the model\n",
    "from piq import ssim, psnr\n",
    "\n",
    "def validate_model(model, valid_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_ssim = 0.0\n",
    "    running_psnr = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(valid_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Normalize outputs and labels to [0, 1] for SSIM and PSNR calculations\n",
    "            outputs = torch.clamp(outputs, 0, 1)\n",
    "            labels = torch.clamp(labels, 0, 1)\n",
    "\n",
    "            # Calculate SSIM and PSNR for each batch\n",
    "            batch_ssim = ssim(outputs, labels, data_range=1.0).item()\n",
    "            batch_psnr = psnr(outputs, labels, data_range=1.0).item()\n",
    "            running_ssim += batch_ssim\n",
    "            running_psnr += batch_psnr\n",
    "\n",
    "        avg_loss = running_loss / len(valid_loader)\n",
    "        avg_ssim = running_ssim / len(valid_loader)\n",
    "        avg_psnr = running_psnr / len(valid_loader)\n",
    "        \n",
    "    return avg_loss, avg_ssim, avg_psnr\n",
    "\n",
    "# Main training loop with plotting\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    valid_loss, valid_ssim, valid_psnr = validate_model(model, valid_loader, criterion, device)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(valid_loss)\n",
    "\n",
    "    # Displaying the metrics\n",
    "    epoch_log = f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}, Valid SSIM: {valid_ssim:.4f}, Valid PSNR: {valid_psnr:.4f}'\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    # Check and save the best model\n",
    "    if valid_loss < best_val_loss:\n",
    "        best_val_loss = valid_loss\n",
    "        best_model_path = f'../Models/best_FocusNet_norm.pth'\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        epoch_log += f\", Best model saved with validation loss: {best_val_loss:.4f} at {best_model_path}\"\n",
    "        print(f\"Best model saved with validation loss: {best_val_loss:.4f}.......\")\n",
    "        best_model_epoch = epoch  # Update the best model epoch\n",
    "\n",
    "\n",
    "    # Save checkpoint at specific intervals\n",
    "    if (epoch + 1) % checkpoint_interval == 0:\n",
    "        checkpoint_filename = f'../Models/checkpoints/FocusNet_norm_epoch_{epoch+1}.pth'\n",
    "        torch.save(model.state_dict(), checkpoint_filename)\n",
    "        print(f\"Checkpoint saved at epoch {epoch+1}\")\n",
    "        \n",
    "    # Update verbose logs\n",
    "    verbose_logs.append(epoch_log)\n",
    "\n",
    "    # Live plot\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "\n",
    "    # Add a marker for the best model\n",
    "    if best_model_epoch > 0:\n",
    "        plt.scatter(best_model_epoch, val_losses[best_model_epoch], color='red', label='Best Model')\n",
    "\n",
    "    plt.title(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    # Print all verbose logs\n",
    "    for log in verbose_logs:\n",
    "        print(log)\n",
    "\n",
    "# Save the final model\n",
    "final_model_filename = '../Models/final_FocusNet_norm.pth'\n",
    "torch.save(model.state_dict(), final_model_filename)\n",
    "print(\"Final model saved & training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the trained model\n",
    "# torch.save(model.state_dict(), '../../Models/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of cubes and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = HyperAttention(in_channels=3, out_channels=31).to(device).float()  # Adjust out_channels to match the target label size\n",
    "# model.load_state_dict(torch.load('../Models/best_HyperAttention_fft.pth', map_location=device))\n",
    "model.eval() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict on a single file with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# image_path = \"C:/Users/user/Desktop/HSI/dataset/ICASSP2024-SPGC/Hyper-Skin(RGB,VIS)/test/RGB_CIE/p012_neutral_front.jpg\"\n",
    "image_path = 'C:/Users/user/Desktop/Research/NTIRE_2022/NTIRE_2022/Test_RGB/ARAD_1K_0951.jpg'\n",
    "image = Image.open(image_path)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations to convert and preprocess the image\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),  # Resize the image to match your model's input size\n",
    "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "])\n",
    "\n",
    "# Apply the transformations to the image\n",
    "input_data = preprocess(image)\n",
    "\n",
    "# Add an extra dimension to match the batch size (1 image in this case)\n",
    "input_data = input_data.unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    input_data = input_data.to(device)\n",
    "    output = model(input_data)\n",
    "    \n",
    "print('input data max',input_data.max())\n",
    "print('input data min',input_data.min())\n",
    "print(output.shape)\n",
    "print('output max',output.max())\n",
    "print('output min',output.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save .mat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'output' is the result from your model and has shape [1, 31, 482, 512]\n",
    "# Remove the batch dimension if it exists\n",
    "if len(output.shape) > 3:\n",
    "    output = output.squeeze(0)\n",
    "\n",
    "num_channels = output.shape[0]\n",
    "num_rows = 8  # You can adjust this based on your preference\n",
    "num_cols = (num_channels + num_rows - 1) // num_rows  # Calculate the number of columns\n",
    "\n",
    "plt.figure(figsize=(16, 12))  # Adjust the figure size as needed\n",
    "\n",
    "for i in range(num_channels):\n",
    "    plt.subplot(num_rows, num_cols, i + 1)\n",
    "    channel_data = output[i].cpu().numpy()  # Convert the channel data to a NumPy array\n",
    "    plt.imshow(channel_data, cmap='gray')  # Display the image in grayscale\n",
    "    plt.title(f'Channel {i + 1}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Define the path to the .mat file where you want to save the output as a cube\n",
    "output_mat_file = \"rgb_2.mat\"  # Provide the desired file path\n",
    "\n",
    "# Assuming 'output' is a PyTorch tensor\n",
    "output_np = output.cpu().numpy()  # Convert the CUDA tensor to a NumPy array\n",
    "\n",
    "# Create the .mat file using h5py and save the data without rotation\n",
    "with h5py.File(output_mat_file, 'w') as mat_file:\n",
    "    # Save the data without rotation\n",
    "    mat_file.create_dataset('cube', data=output_np[0])  # Assuming you want to save the first element\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the output predicted .mat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Define the path to the .mat file\n",
    "mat_file_path = \"rgb_2.mat\"\n",
    "\n",
    "# Open the .mat file using h5py\n",
    "mat_contents = h5py.File(mat_file_path, 'r')\n",
    "\n",
    "# Access the data by the key \"cube\"\n",
    "cube_data = mat_contents[\"cube\"]\n",
    "\n",
    "# Convert the data to a NumPy array\n",
    "output = cube_data[()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Check if the output has a batch dimension and remove it if it exists\n",
    "if len(output.shape) > 3:\n",
    "    output = output[0]\n",
    "\n",
    "num_channels = output.shape[0]\n",
    "num_rows = 8  # You can adjust this based on your preference\n",
    "num_cols = (num_channels - 1) // num_rows + 1  # Calculate the number of columns\n",
    "\n",
    "plt.figure(figsize=(16, 12))  # You can adjust the figure size as needed\n",
    "\n",
    "for i in range(num_channels):\n",
    "    plt.subplot(num_rows, num_cols, i + 1)\n",
    "    channel_data = output[i]  # Use the NumPy array directly\n",
    "    plt.imshow(channel_data, cmap='gray')\n",
    "    plt.title(f'Channel {i + 1}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bigger visulaization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the path to the .mat file\n",
    "mat_file_path = \"rgb_2.mat\"\n",
    "\n",
    "# Open the .mat file using h5py\n",
    "mat_contents = h5py.File(mat_file_path, 'r')\n",
    "\n",
    "# Access the data by the key \"cube\"\n",
    "cube_data = mat_contents[\"cube\"]\n",
    "\n",
    "# Convert the data to a NumPy array\n",
    "output = cube_data[()]\n",
    "\n",
    "# Check if the output has a batch dimension and remove it if it exists\n",
    "if len(output.shape) > 3:\n",
    "    output = output[0]\n",
    "\n",
    "num_channels = output.shape[0]\n",
    "\n",
    "# Set the figure size to display images in a single column\n",
    "plt.figure(figsize=(6, 6 * num_channels))  # Adjust the height based on the number of channels\n",
    "\n",
    "for i in range(num_channels):\n",
    "    plt.subplot(num_channels, 1, i + 1)  # Display images in a single column\n",
    "    channel_data = output[i]  # Convert the tensor to a NumPy array\n",
    "#     channel_data = np.rot90(channel_data, k=3)  # Rotate counterclockwise by 90 degrees\n",
    "    plt.imshow(channel_data, cmap='gray', origin='upper')  # Specify origin='upper' to prevent rotation\n",
    "    plt.title(f'Channel {i + 1}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predictions on all test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# from PIL import Image\n",
    "# import torch\n",
    "# import torchvision.transforms as transforms\n",
    "# import h5py\n",
    "# import numpy as np\n",
    "\n",
    "# model = HyperAttention(in_channels=4, out_channels=61).to(device).float()  # Adjust out_channels to match the target label size\n",
    "# model.load_state_dict(torch.load('../Models/Aug_HyperAttention_fft_470e.pth'))\n",
    "# model.eval() \n",
    "\n",
    "# input_folder = \"../Dataset/ICASSP2024-SPGC/Hyper-Skin(MSI,NIR)/test/MSI_CIE\" # Replace this with the path the input test folder\n",
    "# output_folder = \"./output/Aug_HyperAttention_fft_470e\" # Replace with the path to your output folder\n",
    "\n",
    "# # Make sure the output folder exists\n",
    "# os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# # Define the preprocessing transformation\n",
    "# preprocess = transforms.Compose([\n",
    "#     transforms.Resize((1024, 1024)),\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# # Loop through all the image files in the input folder\n",
    "# for filename in os.listdir(input_folder):\n",
    "#     if filename.endswith(\".mat\"):  # Assuming you have .mat files for 4-channel input\n",
    "#         # Load the .mat file\n",
    "#         mat_file_path = os.path.join(input_folder, filename)\n",
    "\n",
    "#         # Load the .mat file using h5py\n",
    "#         mat_file = h5py.File(mat_file_path, 'r')\n",
    "\n",
    "#         # Access and load the 'cube' dataset\n",
    "#         input_data = mat_file['cube']  # Use the correct dataset name\n",
    "\n",
    "#         # Convert the data to a NumPy array\n",
    "#         input_data = np.array(input_data)\n",
    "\n",
    "#         # Convert the NumPy array to a PyTorch tensor\n",
    "#         input_data = torch.from_numpy(input_data)\n",
    "\n",
    "#         # Add an extra dimension to match the batch size (1 image in this case)\n",
    "#         input_data = input_data.unsqueeze(0)\n",
    "\n",
    "#         # Ensure that the input data and model have the same data type\n",
    "#         input_data = input_data.to(device).float()\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             # Get model predictions\n",
    "#             output = model(input_data)\n",
    "\n",
    "#         # Create the output .mat file\n",
    "#         output_mat_file = os.path.join(output_folder, os.path.splitext(filename)[0] + \".mat\")\n",
    "\n",
    "#         # Convert the output to a NumPy array\n",
    "#         output_np = output.cpu().numpy()  # Move the output to the CPU and then convert to NumPy\n",
    "\n",
    "#         # Save the data as a .mat file\n",
    "#         with h5py.File(output_mat_file, 'w') as mat_file:\n",
    "#             mat_file.create_dataset('cube', data=output_np[0])\n",
    "\n",
    "#         print(f\"Processed {filename} and saved as {os.path.basename(output_mat_file)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## val sam calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from piq import ssim\n",
    "\n",
    "criterion = SAMLoss()\n",
    "# Define the RMSE Loss Function\n",
    "def rmse_loss(outputs, targets):\n",
    "    mse = torch.mean((outputs - targets) ** 2)\n",
    "    rmse = torch.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "# Define the PSNR Loss Function\n",
    "def psnr_loss(outputs, targets, max_pixel=1.0):  # Assuming normalized data [0, 1]\n",
    "    mse = torch.mean((outputs - targets) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    psnr = 20 * math.log10(max_pixel) - 10 * math.log10(mse)\n",
    "    return psnr\n",
    "\n",
    "# Assuming the model is already in evaluation mode and loaded\n",
    "model.eval()\n",
    "\n",
    "# Initialize variables to store total losses\n",
    "total_sam_loss = 0.0\n",
    "total_ssim = 0.0\n",
    "total_rmse = 0.0\n",
    "total_psnr = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (x_val, y_val) in enumerate(valid_loader):\n",
    "        x_val, y_val = x_val.to(device).float(), y_val.to(device).float()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs_val = model(x_val)\n",
    "\n",
    "        # Ensure output size matches target size\n",
    "        outputs_val = torch.nn.functional.interpolate(outputs_val, size=y_val.shape[2:], mode='bilinear', align_corners=False)\n",
    "\n",
    "        # Min-max normalization for outputs and targets\n",
    "        outputs_val_norm = (outputs_val - outputs_val.min()) / (outputs_val.max() - outputs_val.min() + 1e-8)\n",
    "        y_val_norm = (y_val - y_val.min()) / (y_val.max() - y_val.min() + 1e-8)\n",
    "\n",
    "        # Calculate losses\n",
    "        sam_loss = criterion(outputs_val_norm, y_val_norm)\n",
    "        ssim_val = ssim(outputs_val_norm, y_val_norm, data_range=1.0)\n",
    "        rmse_val = rmse_loss(outputs_val_norm, y_val_norm)\n",
    "        psnr_val = psnr_loss(outputs_val_norm, y_val_norm)\n",
    "\n",
    "        # Accumulate the total losses\n",
    "        total_sam_loss += sam_loss.item()\n",
    "        total_ssim += ssim_val.item()\n",
    "        total_rmse += rmse_val.item()\n",
    "        total_psnr += psnr_val\n",
    "\n",
    "# Calculate the average losses over all batches\n",
    "avg_sam_loss = total_sam_loss / len(valid_loader)\n",
    "avg_ssim = total_ssim / len(valid_loader)\n",
    "avg_rmse = total_rmse / len(valid_loader)\n",
    "avg_psnr = total_psnr / len(valid_loader)\n",
    "\n",
    "# Print the average losses\n",
    "print(f\"Average SAM Loss: {avg_sam_loss:.4f}\")\n",
    "print(f\"Average SSIM: {avg_ssim:.4f}\")\n",
    "print(f\"Average RMSE: {avg_rmse:.4f}\")\n",
    "print(f\"Average PSNR: {avg_psnr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming model is already loaded and in evaluation mode\n",
    "model.eval()\n",
    "criterion = SAMLoss()\n",
    "\n",
    "# Define a variable to store the total loss\n",
    "total_val_loss = 0.0\n",
    "\n",
    "# Iterate over the validation loader\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (x_val, y_val) in enumerate(valid_loader):\n",
    "        x_val, y_val = x_val.to(device).float(), y_val.to(device).float()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs_val = model(x_val)\n",
    "        \n",
    "        # You may need to apply the same interpolation to outputs_val as in the training loop\n",
    "        outputs_val = torch.nn.functional.interpolate(outputs_val, size=(482, 512), mode='bilinear', align_corners=False)\n",
    "\n",
    "        # Calculate the loss\n",
    "        val_loss = criterion(outputs_val, y_val)\n",
    "\n",
    "        # Accumulate the total loss\n",
    "        total_val_loss += val_loss.item()\n",
    "\n",
    "# Calculate the average validation loss\n",
    "avg_val_loss = total_val_loss / len(valid_loader)\n",
    "\n",
    "# Print or use the average validation loss as needed\n",
    "print(f\"Average Validation Loss: {avg_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train sam loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming model is already loaded and in evaluation mode\n",
    "model.eval()\n",
    "criterion = SAMLoss()\n",
    "# Define a variable to store the total loss\n",
    "total_train_loss = 0.0\n",
    "\n",
    "# Iterate over the training loader\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (x_train, y_train) in enumerate(train_loader):  # Use train_loader instead of val_loader\n",
    "        x_train, y_train = x_train.to(device).float(), y_train.to(device).float()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs_train = model(x_train)\n",
    "        \n",
    "        # You may need to apply the same interpolation to outputs_train as in the training loop\n",
    "        outputs_train = torch.nn.functional.interpolate(outputs_train,size=(482, 512), mode='bilinear', align_corners=False)\n",
    "\n",
    "        # Calculate the loss\n",
    "        train_loss = criterion(outputs_train, y_train)\n",
    "\n",
    "        # Accumulate the total loss\n",
    "        total_train_loss += train_loss.item()\n",
    "\n",
    "# Calculate the average training loss\n",
    "avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "# Print or use the average training loss as needed\n",
    "print(f\"Average Training Loss: {avg_train_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the model is in evaluation mode and loaded\n",
    "model.eval()\n",
    "\n",
    "# Initialize variables to store total losses for training data\n",
    "total_sam_loss_train = 0.0\n",
    "total_ssim_train = 0.0\n",
    "total_rmse_train = 0.0\n",
    "total_psnr_train = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (x_train, y_train) in enumerate(train_loader):\n",
    "        x_train, y_train = x_train.to(device).float(), y_train.to(device).float()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs_train = model(x_train)\n",
    "\n",
    "        # Ensure output size matches target size\n",
    "        outputs_train = torch.nn.functional.interpolate(outputs_train, size=y_train.shape[2:], mode='bilinear', align_corners=False)\n",
    "\n",
    "        # Min-max normalization for outputs and targets\n",
    "        outputs_train_norm = (outputs_train - outputs_train.min()) / (outputs_train.max() - outputs_train.min() + 1e-8)\n",
    "        y_train_norm = (y_train - y_train.min()) / (y_train.max() - y_train.min() + 1e-8)\n",
    "\n",
    "        # Calculate losses\n",
    "        sam_loss_train = criterion(outputs_train_norm, y_train_norm)\n",
    "        ssim_train = ssim(outputs_train_norm, y_train_norm, data_range=1.0)\n",
    "        rmse_train = rmse_loss(outputs_train_norm, y_train_norm)\n",
    "        psnr_train = psnr_loss(outputs_train_norm, y_train_norm)\n",
    "\n",
    "        # Accumulate the total losses for training data\n",
    "        total_sam_loss_train += sam_loss_train.item()\n",
    "        total_ssim_train += ssim_train.item()\n",
    "        total_rmse_train += rmse_train.item()\n",
    "        total_psnr_train += psnr_train\n",
    "\n",
    "# Calculate the average losses over all training batches\n",
    "avg_sam_loss_train = total_sam_loss_train / len(train_loader)\n",
    "avg_ssim_train = total_ssim_train / len(train_loader)\n",
    "avg_rmse_train = total_rmse_train / len(train_loader)\n",
    "avg_psnr_train = total_psnr_train / len(train_loader)\n",
    "\n",
    "# Print the average losses for training data\n",
    "print(f\"Average SAM Loss on Training Data: {avg_sam_loss_train:.4f}\")\n",
    "print(f\"Average SSIM on Training Data: {avg_ssim_train:.4f}\")\n",
    "print(f\"Average RMSE on Training Data: {avg_rmse_train:.4f}\")\n",
    "print(f\"Average PSNR on Training Data: {avg_psnr_train:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
